# Multi-Agent RAG Orchestrator v4.2 - Constitution

**Version**: 4.2.0
**Date**: 2025-11-18
**Status**: Active
**Scope**: All development, deployment, and maintenance activities

---

## Purpose

This constitution establishes the **non-negotiable principles** that govern the design, implementation, and evolution of the Multi-Agent RAG Workflow Orchestrator v4.2. These principles ensure the system remains robust, observable, cost-effective, privacy-compliant, and production-ready.

**All architectural decisions, code changes, and operational practices MUST align with these principles.**

---

## Core Principles

### Principle I: Visual-First Design

**Statement**: All agentic workflows MUST be visually representable in n8n, ensuring clarity, intuitive debugging, and accessibility for both technical and non-technical stakeholders.

**Rationale**:
- Visual workflows reduce cognitive load and improve maintainability
- Non-technical stakeholders can understand and validate business logic
- Debugging is faster with visual execution traces

**Implementation Requirements**:
- ✅ All agent logic implemented as n8n node configurations
- ✅ Complex logic encapsulated in well-documented Code Nodes
- ✅ State passed explicitly between nodes (no hidden globals)
- ✅ Execution paths clearly visible in workflow canvas
- ❌ No hidden orchestration logic outside n8n
- ❌ No implicit state management

**Example**:
```javascript
// ✅ GOOD: Explicit state in n8n Code Node
const agentState = {
  task: $input.item.json.task,
  context: $input.item.json.context,
  iteration: ($input.item.json.iteration || 0) + 1
};

return { json: agentState };
```

---

### Principle II: Open-Source First & LLM-Agnostic Architecture

**Statement**: The system MUST prioritize open-source LLMs (Tier 0/1) for 80%+ of operations while maintaining provider-agnostic abstraction for flexibility, cost optimization, and offline capabilities.

**Rationale** (v4.2 Enhancement):
- Open-source models (Ollama, Fireworks) provide 80% of capability at 0-5% of premium cost
- Provider abstraction enables automatic failover and 99.9% uptime
- Vendor lock-in avoidance ensures long-term sustainability
- Privacy mode requires local-only execution

**Implementation Requirements**:
- ✅ Provider abstraction layer with pluggable backends
- ✅ Tier-based routing: 45% Tier 0, 35% Tier 1, 13% Tier 3, 5% Tier 2, 2% Tier 4
- ✅ Health checks and automatic failover (99.9% uptime SLA)
- ✅ Privacy mode enforces Tier 0/2 only (local models)
- ✅ Support for Ollama, Fireworks, Together, Anthropic, OpenAI, Jan
- ❌ No hardcoded model names outside configuration
- ❌ No direct API calls without provider abstraction

**Tier Distribution** (v4.2):
| Tier | Models | Cost | Usage % | Privacy Mode |
|------|--------|------|---------|--------------|
| 0 | Ollama 3B-70B | $0 | 45% | ✅ Allowed |
| 1 | Fireworks, Together | $0.20-0.80/M | 35% | ❌ Blocked |
| 2 | Ollama Vision 90B | $0 (VPS) | 5% | ✅ Allowed |
| 3 | Claude, Gemini | $3-15/M | 13% | ❌ Blocked |
| 4 | RunPod, Salad | $0.69-2/hr | 2% | ❌ Blocked |

---

### Principle III: Fail-Safe Operations

**Statement**: Every LLM call, tool execution, and data retrieval MUST implement robust error handling, automatic retries with exponential backoff, and graceful degradation to ensure system resilience.

**Rationale**:
- External services are inherently unreliable
- User-facing systems must never crash on single failures
- Observability requires error capture and analysis

**Implementation Requirements**:
- ✅ Exponential backoff for all external API calls (2s, 4s, 8s, 16s)
- ✅ Maximum 4 retry attempts before failover
- ✅ Provider failover chain: Tier N → Tier N+1 → Tier 3
- ✅ Graceful degradation: return partial results with warnings
- ✅ Circuit breakers for repeatedly failing services
- ✅ Error logging with full context (request, response, trace)
- ❌ No unhandled exceptions in production code
- ❌ No silent failures without alerts

**Example**:
```python
# ✅ GOOD: Retry with exponential backoff
@retry(max_attempts=4, backoff=[2, 4, 8, 16])
async def call_llm_with_failover(tier, prompt):
    try:
        return await provider_router.route(tier, prompt)
    except ProviderUnavailable as e:
        logger.warning(f"Tier {tier} failed: {e}, trying Tier {tier+1}")
        return await provider_router.route(tier + 1, prompt)
    except Exception as e:
        logger.error(f"Critical failure: {e}", exc_info=True)
        await alert_on_call()
        raise
```

---

### Principle IV: Cost-Conscious Design

**Statement**: Token usage and API costs MUST be actively managed through monitoring, prompt optimization, caching, streaming, hard budget limits, and prioritizing local inference.

**Rationale** (v4.2 Enhancement):
- API costs can spiral out of control without limits ($1000s/month)
- Budget enforcement prevents financial surprises
- Streaming with early termination saves 15-30% on costs
- Context compression reduces RAG costs by 84%

**Implementation Requirements**:
- ✅ Redis budget pools with hard limits (daily, weekly, monthly)
- ✅ Pre-flight budget checks before expensive operations
- ✅ Real-time cost tracking and dashboards
- ✅ Streaming-first design with early termination detection
- ✅ Context compression before Tier 3 calls (<8k tokens)
- ✅ Architect/Executor pattern (Tier 3 plans, Tier 0/1 executes)
- ✅ Caching for repeated queries (Redis, 15-min TTL)
- ✅ Budget utilization alerts (80%, 90%, 95%)
- ❌ No unbounded LLM calls
- ❌ No cost-blind feature development

**Cost Target** (v4.2):
- Standard Mode: $6-8/month per user (100 tasks)
- Privacy Mode: $75/month fixed VPS cost (0 API costs)
- Savings vs v4.0: 17% (Open-Source First strategy)

**Example**:
```python
# ✅ GOOD: Budget-aware execution
async def execute_with_budget(user_id, task, tier):
    estimated_cost = estimate_cost(tier, task)

    if not await budget_enforcer.check_budget(user_id, 'daily', estimated_cost):
        raise BudgetExceededError(
            f'Daily budget would be exceeded. '
            f'Estimated: ${estimated_cost:.4f}'
        )

    # Stream with early termination
    accumulated = ''
    async for chunk in stream_llm(tier, task):
        if chunk.type == 'termination':
            break  # Save cost
        accumulated += chunk.content

    await budget_enforcer.deduct_budget(user_id, 'daily', chunk.cost)
    return accumulated
```

---

### Principle V: Observable Agent Flows

**Statement**: Every step of the agent workflow MUST be traceable and debuggable with structured logging, LLM prompt/response capture, RAG retrieval details, and comprehensive execution metrics.

**Rationale** (v4.2 Enhancement):
- Production issues require full execution traces
- LLMOps feedback loop enables continuous improvement
- Cost attribution requires detailed metrics
- A/B testing depends on reliable data collection

**Implementation Requirements**:
- ✅ PostgreSQL logging for ALL LLM invocations (30-day retention)
- ✅ Structured logs with: tier, model, tokens, cost, latency, success, task_type
- ✅ LLMOps dashboard with real-time metrics
- ✅ Execution trace IDs linking all steps in a workflow
- ✅ RAG retrieval logging: query, chunks retrieved, scores, reranking
- ✅ Tool execution logging: tool name, params, result, duration
- ✅ Audit logs for privacy mode operations (local-only)
- ✅ Historical analysis for tier optimization
- ❌ No production execution without logging
- ❌ No PII in logs (sanitize user data)

**Logging Schema**:
```sql
CREATE TABLE llm_invocations (
    id SERIAL PRIMARY KEY,
    trace_id UUID NOT NULL,
    timestamp TIMESTAMP DEFAULT NOW(),
    user_id VARCHAR(255),
    tier INTEGER,
    model VARCHAR(255),
    prompt_tokens INTEGER,
    completion_tokens INTEGER,
    cost DECIMAL(10, 6),
    latency_ms INTEGER,
    success BOOLEAN,
    error TEXT,
    task_type VARCHAR(100),
    privacy_mode BOOLEAN
);

CREATE INDEX idx_trace ON llm_invocations(trace_id);
CREATE INDEX idx_user_tier ON llm_invocations(user_id, tier);
CREATE INDEX idx_timestamp ON llm_invocations(timestamp);
```

---

### Principle VI: Production-Grade Reliability

**Statement**: The system MUST maintain 99.9% uptime through provider failover, health monitoring, circuit breakers, and graceful degradation.

**Rationale** (v4.2 Enhancement):
- Enterprise users expect always-on availability
- Multi-provider redundancy prevents single points of failure
- Health checks enable proactive issue detection

**Implementation Requirements**:
- ✅ Provider health checks (5-min interval, 5-min cache)
- ✅ Automatic failover to backup provider (<2s)
- ✅ Circuit breakers for failing services (3 failures → open)
- ✅ Blue-green deployments for zero-downtime updates
- ✅ Database connection pooling and retry logic
- ✅ Redis for distributed state management
- ✅ Monitoring and alerting (Prometheus + Grafana)
- ✅ SLA tracking and reporting
- ❌ No single provider dependency
- ❌ No synchronous blocking operations

**Uptime SLA**: 99.9% (43 minutes downtime/month max)

---

### Principle VII: Privacy by Design

**Statement**: The system MUST provide a privacy mode that enforces 100% local execution (Tier 0/2 only), GDPR/HIPAA compliance, MCP server sandboxing, and comprehensive audit logging.

**Rationale** (v4.2 Enhancement):
- Regulated industries require on-premises data processing
- GDPR Article 25 mandates Privacy by Design
- Users deserve control over data locality

**Implementation Requirements**:
- ✅ Privacy mode toggle in UI (per-session, per-user)
- ✅ Privacy mode blocks all Tier 1/3/4 calls (external APIs)
- ✅ MCP servers with sandboxed filesystem access
- ✅ Jan integration for OpenAI-compatible local API
- ✅ Local-only audit logs (append-only, encrypted)
- ✅ No telemetry in privacy mode
- ✅ Clear UI indicators when privacy mode is active
- ✅ Data residency guarantees (all data stays local)
- ❌ No cloud API calls in privacy mode
- ❌ No data exfiltration mechanisms

**Privacy Stack**:
- Tier 0: Ollama (localhost:11434)
- Tier 2: Ollama Vision (VPS)
- Jan: OpenAI API (localhost:1337)
- MCP Servers: Filesystem, Git, Memory (localhost:3001-3003)

**Compliance**:
- GDPR Article 6 (Lawful Basis), Article 25 (Privacy by Design)
- HIPAA Safe Harbor (local-only PHI processing)

---

### Principle VIII: RAG Accuracy & Anti-Hallucination

**Statement**: The RAG pipeline MUST maximize retrieval accuracy through hybrid search, semantic chunking, reranking, and context compression to minimize hallucination.

**Rationale** (v4.2 Enhancement):
- Single-stage semantic search misses keyword matches (40% accuracy loss)
- Fixed chunking fragments context across boundaries
- Large contexts cause hallucination in narrow-context models (Claude)

**Implementation Requirements**:
- ✅ Hybrid search: 70% semantic + 30% keyword (BM25)
- ✅ Semantic chunking by sentence similarity (not fixed size)
- ✅ Two-stage retrieval: over-fetch (20) → rerank → top-5
- ✅ Context compression for Tier 3 (<8k tokens for Claude)
- ✅ Metadata filtering (doc_type, date, source) pre-retrieval
- ✅ Citation tracking (source, page, chunk ID)
- ✅ Confidence scoring for answers
- ✅ Fallback to "I don't know" when confidence <0.6
- ❌ No pure semantic search without keyword augmentation
- ❌ No answers without source citations

**Accuracy Target**:
- Precision@5: ≥85% (v4.2) vs 65% (v4.1)
- Recall@10: ≥90% (v4.2) vs 75% (v4.1)
- Hallucination Rate: <5%

---

### Principle IX: Web Agent Privacy & Performance

**Statement**: Web agents MUST use privacy-hardened Playwright with stealth mode, fingerprint randomization, tracker blocking, and LLM-driven autonomous browsing.

**Rationale** (v4.2 Enhancement):
- Standard Playwright is detectable (CAPTCHAs, rate limits)
- Browser fingerprinting violates user privacy
- Static scripts are brittle and require constant maintenance
- LLM-driven agents adapt to page changes automatically

**Implementation Requirements**:
- ✅ Playwright with stealth plugin (anti-detection)
- ✅ Random fingerprints: user agent, viewport, canvas noise
- ✅ Tracker blocking: Google Analytics, Facebook Pixel, etc.
- ✅ LLM-driven action-perception loop (autonomous browsing)
- ✅ LLM-as-judge for task success validation
- ✅ Tier 0/2 (Ollama Vision) for privacy mode browsing
- ✅ Session persistence (cookies, auth state)
- ❌ No static Playwright scripts for complex tasks
- ❌ No tracking scripts or fingerprinting telemetry

**Performance Target**:
- Task Success Rate: ≥90% (v4.2) vs 60% (v4.1)
- Average Task Duration: 12-15s (v4.2) vs 45s (v4.1)
- CAPTCHA Encounters: <5% of sessions

---

### Principle X: Multi-Agent Coordination

**Statement**: Multi-agent workflows MUST use message-driven architecture with composable tool workbenches, enabling scalable coordination of 10+ concurrent agents.

**Rationale** (v4.2 Enhancement):
- Synchronous agent calls don't scale beyond 3-4 agents
- Event-driven patterns enable loose coupling and parallelism
- Tool workbenches allow dynamic capability composition

**Implementation Requirements**:
- ✅ Event-driven agent coordinator (EventEmitter pattern)
- ✅ Message queue for broadcast and direct routing
- ✅ Agent workbenches with composable tool registration
- ✅ MCP server auto-discovery and capability registration
- ✅ Privacy-aware tool filtering per agent
- ✅ Tool usage analytics and cost attribution
- ✅ Message persistence for replay and debugging
- ❌ No synchronous blocking agent calls
- ❌ No hardcoded tool dependencies

**Scalability Target**:
- Concurrent Agents: 10+ (v4.2) vs 3-4 (v4.1)
- Message Throughput: 1000+ messages/sec
- Coordination Latency: <100ms per hop

---

### Principle XI: Continuous Improvement via LLMOps

**Statement**: The system MUST implement a feedback loop that analyzes production data to optimize tier routing, prompt engineering, and workflow efficiency over time.

**Rationale** (v4.2 Enhancement):
- Historical data reveals optimal tier assignments per task type
- A/B testing enables evidence-based prompt improvement
- Cost/performance tradeoffs vary by workload

**Implementation Requirements**:
- ✅ PostgreSQL analytics on 30 days of invocation history
- ✅ Automated tier recommendations based on success rate + cost
- ✅ A/B testing framework for workflow versions
- ✅ Statistical significance testing (p < 0.05)
- ✅ Prompt versioning with performance tracking
- ✅ Automated rollout of winning variants
- ✅ Weekly reports: cost trends, accuracy, latency
- ❌ No manual tier selection without data justification
- ❌ No prompt changes without A/B validation

**Improvement Cycle**:
1. Collect: Log all invocations
2. Analyze: Aggregate by task_type, tier, model
3. Test: A/B test proposed changes
4. Deploy: Roll out if statistically significant improvement
5. Monitor: Track impact on KPIs

---

## Principle Hierarchy

In case of conflicts between principles, the following hierarchy applies:

1. **Principle VII (Privacy by Design)** - Privacy is non-negotiable
2. **Principle III (Fail-Safe Operations)** - Reliability over features
3. **Principle V (Observable Agent Flows)** - Can't fix what you can't see
4. **Principle VIII (RAG Accuracy)** - Correct answers > fast answers
5. **Principle IV (Cost-Conscious Design)** - Sustainability matters
6. **All other principles** - Equal priority

---

## Constitutional Amendments

This constitution may be amended only under the following conditions:

1. **Proposal**: Written proposal with rationale and impact analysis
2. **Review**: Technical review by architecture team (minimum 3 reviewers)
3. **Approval**: Unanimous approval by stakeholders
4. **Migration**: Migration plan for existing systems
5. **Documentation**: Updated constitution with version bump

**Amendment History**:
- v4.0.0 (2024-11-15): Initial constitution (Principles I-V, X)
- v4.1.0 (2024-11-17): Added Principles X (RAG), XI (Privacy Mode), XIII (Web Chat UI)
- v4.2.0 (2025-11-18): Comprehensive revision based on 8 production systems analysis
  - Enhanced Principle II (Open-Source First)
  - New Principle VI (Production-Grade Reliability)
  - New Principle VII (Privacy by Design - consolidated from v4.1 Principle XI)
  - New Principle VIII (RAG Accuracy - evolved from v4.1 Principle X)
  - New Principle IX (Web Agent Privacy & Performance)
  - New Principle X (Multi-Agent Coordination - evolved from v4.0 Principle X)
  - New Principle XI (Continuous Improvement via LLMOps)

---

## Enforcement

**All pull requests MUST include a "Constitutional Compliance" section** demonstrating alignment with relevant principles.

**Template**:
```markdown
## Constitutional Compliance

### Principles Addressed
- [ ] Principle II (Open-Source First): Uses provider abstraction layer
- [ ] Principle IV (Cost-Conscious): Implements budget check before execution
- [ ] Principle V (Observable): Logs all invocations to PostgreSQL

### Principles Impacted
- Principle VIII (RAG Accuracy): Improves hybrid search weighting

### Justification
This PR enhances the hybrid search algorithm by adjusting the semantic:keyword
weight ratio from 70:30 to 75:25 based on A/B test results showing 8% precision
improvement (FR-178).
```

**Violations** will result in:
1. PR rejection with explanation
2. Required revision before merge
3. Architecture review if systemic issue detected

---

## Review Cycle

This constitution MUST be reviewed:
- After every major version release (vX.0.0)
- Annually (every November)
- When new patterns emerge from production data
- When new compliance requirements are introduced

**Next Scheduled Review**: 2026-11-18

---

**Document Maintainers**: Architecture Team
**Last Reviewed**: 2025-11-18
**Version**: 4.2.0
**Status**: ✅ Active
